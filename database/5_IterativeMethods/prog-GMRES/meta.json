{
    "filename": "prog-GMRES.tex",
    "title": "",
    "subtitle": "",
    "coding": "",
    "mathFields": "",
    "tags": "Linear Systems, Krylov Subspace Methods, Python",
    "relatedExercises": "",
    "solutionLength": "",
    "task": "\\section{GMRES}\n\\begin{enumerate}\n\t\t\\item \\textbf{Arnoldi step:} For given orthonormal vectors $q_1,\\ldots, q_{r-1} \\in \\mathbb{R}^n$ considered as a matrix $Q_{r-1}=[q_1,\\ldots,q_{r-1}]\\in\\mathbb{R}^{n\\times (r-1)}$, and a vector $v\\in\\mathbb{R}^n$, implement a helper function\n\t$$q_r, h_r := \\texttt{Arnoldi\\_step}(Q_{r-1}, v),$$\n\twhich, according to the Arnoldi iteration, appends these vectors (i.e., the matrix $Q_{r-1}$) by an orthonormal vector $q_r$ through orthogonalizing $v$ against $q_1,\\ldots, q_{r-1}$ and also outputs the numbers $h_r := (h_{1,r-1},\\ldots, h_{r,r-1})^\\top \\in \\mathbb{R}^{r}$, where $h_{\\ell, r-1} :=  q_\\ell^\\top v$ for $\\ell \\leq r$. You can then call \\texttt{Arnoldi\\_step}(Q; v) within \\texttt{GMRES(...)}.\n\t\\item \\textbf{GMRES:}\nImplement a function $$x = \\texttt{GMRES(A, b, x0, tol=1e-6, maxiter=None, N=None)},$$\nwhich takes as arguments\n\\begin{itemize}\n\t\\item A : a \\underline{function} evaluating the matrix--vector product $v\\mapsto A\\cdot v$ for some matrix $ A \\in \\mathbb{R}^{n \\times n}$ (not as an array!)\n\t\\item b : a vector $b \\in \\mathbb{R}^ {n}$\n\t\\item x0 : an arbitrary initial guess $x^0 \\in \\mathbb{R}^ {n}$\n\t\\item tol : error tolerance as float, which is set to $10^{-6}$ by default \n\t\\item maxiter : optional maximum number of iterations, which is set to \\texttt{None} by default\n\t\\item N : optional preconditioner as a function (not as an array), for which $N(v)\\approx A^{-1}v$\n\\end{itemize}\nand then solves the system $Ax=b$ by applying the GMRES method as presented in the lecture (see pseudocode \\ref{gmres} below). It shall then return\n\\begin{itemize}\n\t\\item \\texttt{x} : the approximation to the solution.\n%\t\\item \\texttt{error} : list containing all residuals $\\|Ax^k-b\\|_2$\n%\t\\item \\texttt{numiter} : number of iterations that have been performed.\n\\end{itemize}\t\nThe iteration shall break if the residual is tolerably small, i.e., \n$$\\|Ax^k-b\\|_2 < \\ttt{tol}$$\nor the maximum number of iterations \\ttt{maxiter} has been reached.\n\n\n%\t\\item Do not deliver a dense array \\texttt{A} to your solver, but a function \\texttt{A(x)} that evaluates the matrix-vector product.\n%\t\\item Stop the iteration if $\\|Ax_r-b\\|_2 < \\texttt{tol}$ with $\\texttt{tol}:=10^{-6}$.\n%\t\\item Allow for a nonzero initial guess $\\texttt{x0} \\neq 0$.\t\n\t\\item \\textbf{Test} your solver on a random invertible tridiagonal matrix \n\t$$A = \\begin{pmatrix}\n\t* & * \t\t& 0  &\\cdots & 0\\\\\n\t* & *\t\t& *  &\\ddots &  \\vdots\\\\\n\t0 & \\ddots  \t\t&\\ddots   \t &\\ddots  & 0 \\\\\n\t\\vdots    & \\ddots  \t\t&*  \t &* & *\\\\\n\t0 & \\cdots \t&  0  &* &*\\\\\n\t\\end{pmatrix} \\in \\Rnn$$ \n\tand some right-hand side $b$ and initial guess $x_0$ of your choice. Choose different $n$ and check how many iterations you need (potentially many!).\\\\\n\t\\textit{Hint:} You can generate some random diagonals using \\texttt{numpy.random.rand(n)} and then use $$\\texttt{scipy.sparse.diags(diagonals, offsets=[-1,0,1]).tocsr()}$$ to construct a sparse CSR matrix. You can add \\texttt{np.ones(n)} to the main diagonal in order to ``strengthen'' the diagonal of $A$ and thereby to get a better conditioned system. Then implement a function \\texttt{A(x)} that outputs the matrix-vector product \\texttt{A.dot(x)}. \n%\n%\trandom  \\texttt{b = numpy.random.rand(n)}.\n%\tYou can use $$\\texttt{A\\_csr=4*scipy.sparse.eye(n,k=0)-scipy.sparse.eye(n,k=1)-scipy.sparse.eye(n,k=-1)}$$\n%\tand \n\t\\item \\textbf{Preconditioner:} For the same system, run your GMRES routine with a preconditioner of your choice (for example Jacobi $N: v \\mapsto D^{-1}v$). Do you observe any difference in the number of iterations needed? (Don't worry if not!)\n\t\\item \\textbf{Compare} your \\texttt{GMRES} solver to \\texttt{scipy.linalg.solve(A\\_csr.toarray(),b)} for large dimension $n \\geq 10^{5}$ and measure the time needed in each case. Also, find a SciPy implementation of GMRES and compare to yours.\n%\t\\item \\textit{*Bonus:} Do you need to adapt your algorithm if you want to use a preconditioner? \n%\t\\item \\textbf{\\textit{*Bonus:}} Allow for an optional parameter indicating whether $A$ is symmetric. Use the Lanczos iteration instead of Arnoldi, if $A$ is symmetric.\n\\end{enumerate}\n\n\\newpage\n\\begin{algorithm}\n\t\\textbf{INPUT:} $A\\in GL_n(\\mathbb{R})$, $b \\in \\mathbb{R}^n$\\\\\n\t\\textbf{OUTPUT:} approximation $x_r \\in K_r(A,b)$ to the exact solution $A^{-1}b$\\\\~\\\\\n%\t$q_1 := \\frac{b}{\\|b\\|_2}$,\t$Q_1 := [q_1]$\\\\\n%\t$v :=Aq_1,~~\\tilde{q}_1 := \\frac{v}{\\|v\\|_2}$,~~$\\tilde{Q}_1 := [\\tilde{q}_1]$,~~$\\tilde{R}_1 = [\\|v\\|_2]$\\\\\n%\t\\For{$r = 2,...,n$}{\n%\t\t{\\color{gray}// use Arnoldi to find column $q_r$ by orthogonalizing $v$ against $q_1,\\ldots, q_{r-1}$ } \\\\\n%\t\t$q_r, h_{r-1} := \\texttt{Arnoldi\\_step}(Q_{r-1}; v)$ {\\color{gray}//we don't need $h_{r-1}$ }\\\\\n%\t\t$Q_r := [Q_{r-1},q_r]$\\\\\n%\t\t$v:= Aq_r$\\\\\n%\t\t{\\color{gray}// use Arnoldi to find columns $\\tilde{q}_r,~\\widetilde{r}_r$ by orthogonalizing $v$ against $\\tilde{q}_1,\\ldots, \\tilde{q}_{r-1}$ } \\\\\n%$\\tilde{q}_r, \\tilde{r}_r := \\texttt{Arnoldi\\_step}(\\widetilde{Q}_{r-1}; v)$\\\\\n%\t\t$\\widetilde{Q}_r := [\\widetilde{Q}_{r-1},\\widetilde{q}_r]$, $\\widetilde{R}_r := [\\widetilde{R}_{r-1},\\widetilde{r}_r]$\\\\\n%\t\t{\\color{gray}// solve auxiliary least squares problems to obtain coordinates} \\\\\n%\t\t$c_r := \\texttt{solve\\_triangular}(\\widetilde{R}_r,\\widetilde{Q}_r^\\top b )$\\\\\n%\t\t$x_r := Q_r c_r$\n%\t\t\n%\t\t\\If{$ \\|Ax_r - b\\|_2 < \\texttt{tol}$}{\n%\t\t\tbreak\n%\t\t\t\n%\t\t}\n%\t\t\n%\t}\n%\\texttt{return} $x_r$\n\t\\texttt{\\large \\textbf{GMRES}}($A$, $b$, $x_0 = 0$,\\texttt{ tol = 1e-6}, \\texttt{maxiter=None}, $N=I$ ):\\\\\n\t$b := b - Ax_0$ {\\color{gray}//account for initial guess}\\\\\n$A := NA$, $b := Nb$ {\\color{gray}//account for preconditioner}\\\\\n{\\color{gray}//Initialization:}\\\\\n$q_1 := \\frac{b}{\\|b\\|_2}$,\t$Q_1 := [q_1]$\\\\\n$v :=Aq_1$\\\\\n$\\tilde{q}_1 := \\frac{v}{\\|v\\|_2}$,~~$\\tilde{Q}_1 := [\\tilde{q}_1]$,~~$\\tilde{R}_1 = [\\|v\\|_2]$\\\\\n\\For{$r = 2,...,\\min(n,\\texttt{maxiter})$}{\n\t{\\color{gray}//STEP 1: use Arnoldi to find column $q_r$ by orthogonalizing $v$ against $q_1,\\ldots, q_{r-1}$ } \\\\\n\t$q_r, h_{r-1} := \\texttt{Arnoldi\\_step}(Q_{r-1}; v)$ {\\color{gray}//we don't need $h_{r-1}$ in this variant}\\\\\n\t$Q_r := [Q_{r-1},q_r]$\\\\\n\t$v:= Aq_r$\\\\~\\\\\n\t{\\color{gray}//STEP 2: use Arnoldi to find columns $\\tilde{q}_r,~\\widetilde{r}_r$ by orthogonalizing $v$ against $\\tilde{q}_1,\\ldots, \\tilde{q}_{r-1}$ } \n\t$\\tilde{q}_r, \\tilde{r}_r := \\texttt{Arnoldi\\_step}(\\widetilde{Q}_{r-1}; v)$\\\\\n\t$\\widetilde{Q}_r := [\\widetilde{Q}_{r-1},\\widetilde{q}_r]$, $\\widetilde{R}_r := [\\widetilde{R}_{r-1},\\widetilde{r}_r]$\\\\~\\\\\n\t{\\color{gray}//STEP 3: solve auxiliary least squares problems to obtain coordinates} \\\\\n\t$c_r := \\texttt{solve\\_triangular}(\\widetilde{R}_r,\\widetilde{Q}_r^\\top b )$\\\\\n\t$x_r := Q_r c_r$\t\\\\\t\n\t{\\color{gray}//Attention: Evaluate the original residual here:} \\\\\n\t\\If{$ \\|N^{-1}(Ax_r - b)\\|_2 < \\texttt{tol}$}{\n\t\tbreak\n\t}\t\t\n}\n\\texttt{\\textbf{return}} $x_0 + x_r$\n\t\\caption{GMRES}\n\t\\label{gmres}\n\\end{algorithm}",
    "solution": "\\lstinputlisting[numbers=none]{prog-GMRES_solution.py}\n",
    "id": ""
}