{
    "filename": "prog-LinearIterations_JacRich.tex",
    "title": "",
    "subtitle": "",
    "coding": "",
    "mathFields": "",
    "tags": "Linear Systems, Splitting Methods, Python",
    "relatedExercises": "",
    "solutionLength": "",
    "task": "\\section{Splitting Methods: relax. Richardson, relax. Jacobi, Gau\u00df-Seidel and SOR}\n\n\\begin{enumerate}\n\t\t\\item \tImplement a function \n\t\t$$\\verb|x, error, numiter = iter_solve(A, b, x0, method=\"Jacobi\", theta=.1, tol=1e-08, maxiter=50)|$$ \n\t\twhich takes as arguments\n%\t\tThe function shall return an approximate solution of the problem $Ax = b$ after performing $m \\in \\N$ steps of the linear iteration specified by the parameter \\verb|method|.\t\n\t\t\\begin{itemize}\n\t\t\t\\item A : a matrix $A \\in \\mathbb{R}^{n \\times n}$\n\t\t\t\\item b : a vector $b \\in \\mathbb{R}^ {n}$\n\t\t\t\\item x0 : an initial guess $x^0 \\in \\mathbb{R}^ {n}$\n\t\t\t\\item \\texttt{method} : optional parameter to choose between relax. Richardson, weighted Jacobi, Gau\u00df-Seidel and SOR and which is set to \\verb|\"Jacobi\"| by default\n\t\t\t\\item theta : relaxation parameter $\\theta$ which is set to $0.1$ by default\\\\ (note: Gau\u00df--Seidel is SOR with \\texttt{theta=1.0})\n\t\t\t\\item tol : error tolerance as float, which is set to $10^{-8}$ by default \n\t\t\t\\item maxiter : maximum number of iterations, which is set to 50 by default\n\t\t\\end{itemize}\n\t\tand then solves the system $Ax=b$ by applying the specified iterative scheme. It shall then return\n\t\t\\begin{itemize}\n\t\t\t\\item \\texttt{x} : list of all iterates $x^k$\n\t\t\t\\item \\texttt{error} : list containing all residuals $\\|Ax^k-b\\|_2$\n\t\t\t\\item \\texttt{numiter} : number of iterations that have been performed\n\t\t\\end{itemize}\t\n\t\tThe iteration shall break if the residual is tolerably small, i.e., \n\t\t$$\\|Ax^k-b\\|_2 < \\ttt{tol}$$\n\t    or the maximum number of iterations \\ttt{maxiter} has been reached.\\\\~\\\\\n\\textit{Hint:} Implement the element-based formulas for the Jacobi, Gau\u00df-Seidel and SOR method (see previous exercise).\n\t\t\\item \\textbf{2d:} Test \\underline{all} methods on the following two-dimensional setting:\n\t\t$$A = 4 \\begin{pmatrix}\n\t\t2&-1\\\\ -1&2\n\t\t\\end{pmatrix}, ~~b = \\begin{pmatrix}\n\t\t0\\\\0\n\t\t\\end{pmatrix}.$$ \n\t\tWhat is the exact solution $x^*$? Play around with the parameters \\texttt{x0, theta, tol} and \\texttt{maxiter}.\n\t\tAlso create the following two plots for one fixed setting:\n\t\t\\begin{itemize}\n\t\t\t\\item Plot the error $\\|Ax^k - b\\|_2$  for each iterate $x^k \\in \\mathbb{R}^2$, $k=1,\\dots,m$, for \\underline{all} methods into one plot (use different colors).\n\t\t\t\\item Plot the iterates $x^k \\in \\mathbb{R}^2$, $k=1,\\dots,m$, themselves for all methods into one plot (use different colors).\n\t\t\\end{itemize}\n\t\t\\item \\textbf{nd:} Next, test all methods on the higher--dimensional analogue\n\t\t$$\n\t\tA = n^2 \\left(\\begin{array}{rrrrr}                                \n\t\t2 & -1  &0   & \\hdots   & 0 \\\\                                               \n\t\t-1 &  2 & -1  &    &   \\vdots \\\\                                               \n\t\t0&  \\ddots &  \\ddots &\\ddots  &0  \\\\ \n\t\t\\vdots  &    &  -1 &  2 & -1  \\\\ \n\t\t0 &   \\hdots  & 0& -1  &  2 \\\\\n\t\t\\end{array}\\right)\\in \\mathbb{R}^{n \\times n},$$\n\t\tfor different dimensions $n\\in\\N$ and data $b,x^0 \\in \\mathbb{R}^n$ of your choice. Play around with the parameters.\n\t\\end{enumerate}\n\t\\textit{Hint: } Of course, it can happen that the iterations do not converge. Use small values for $\\theta$ when you use the Richardson iteration. This will assure that $\\rho(I-NA)<1$. \n",
    "solution": "\\lstinputlisting[numbers=none]{prog-LinearIterations_JacRich_solution.py}\n",
    "id": ""
}