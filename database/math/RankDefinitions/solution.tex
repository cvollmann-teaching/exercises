{\color{solution}
\textbf{i) $\Rightarrow$ ii):} Pick $r$ independent columns of $A = [a_1,\ldots,a_n]$, say $a_{i_1},\ldots,a_{i_r}$. Then by i) any other column of $A$ can be written as linear combination of $a_{i_1},\ldots,a_{i_r}$, so that $$\text{Im}(A)= \text{span}(a_{1},\ldots,a_{n})= \text{span}(a_{i_1},\ldots,a_{i_r}).$$ Thus the $a_{i_1},\ldots,a_{i_r}$ are a basis of length $r$ for $\text{Im}(A)$, implying ii) by the definition of ``dimension''.\\~\\
\textbf{ii) $\Rightarrow$ i):} 
Let $\text{dim}(\text{Im}(A))= r$. Since any basis of a subspace has the same length, any basis of $\text{Im}(A)$ has length $r$.\\
Now assume $A$ has more than $r$ independent columns. Then by the reasoning from above, these columns would yield another basis of $\text{Im}(A)$ but with length $>r$, which would contradict the fact that any basis has length $r$. Therefore implying i): the maximum number of independent columns in $A$ is $r$. \\~\\
\textbf{ii) $\Leftrightarrow$ iii)} We show that $$\dim(\text{Im}(A)) = \text{number of positive singular values of }A .$$
Let us consider the reduced SVD $A = U_r \Sigma_r V_r^\top$ where $r$ denotes the number of (positive) singular values, $\Sigma_r$ is an invertible diagonal matrix and $U_r$ and $V_r^\top$ have independent (even orthonormal) columns and rows, respectively. Thus
$$\text{Im}(A) = \text{Im}(U_r \Sigma_r V_r^\top). $$
We show that $\Sigma_r V_r^\top$ is surjective, i.e., $\text{rank}(\Sigma_r V_r^\top) = r$. This easily follows from the fact that $(\Sigma_r V_r^\top)^\top = V_r\Sigma_r $ has independent columns and thus $$\text{nullity}(V_r\Sigma_r) = 0 \Leftrightarrow \text{rank}(\Sigma_r V_r^\top) = r.$$ Therefore by the lemma on the image of a product matrix we obtain
$$\text{Im}(A) = \text{Im}(U_r \Sigma_r V_r^\top)= \text{Im}(U_r).$$
Since the columns of $U_r$ are independent they are a basis of length $r$ for $\text{Im}(A)$, i.e., $\dim(\text{Im}(A))=r$=number of (positive) singular values.

 
%Therefore, let $A = U\Sigma V^\top$, then for $x\in \mathbb{R}^n$ we find
%\begin{align*}
%A x =  U\Sigma V^\top x =  U (\Sigma V^\top x) = U\mu,
%\end{align*}
%with
%\begin{align*}
%\mu := \Sigma V^\top x = (\mu_1,\ldots, \mu_r,0,\ldots,0)^\top \in \mathbb{R}^m ~~~(\text{note: $\sigma_j = 0$ for $j \geq r+1$}).
%\end{align*}
%Thus
%\begin{align*}
%\text{Im}(A) 
%&= \{ Ax: x\in \mathbb{R}^n \} = \{ U\mu:  \mu:=\Sigma V^\top x= (\mu_1,\ldots, \mu_r,0,\ldots,0)^\top,~ x \in \mathbb{R}^n \}  \\
%&\stackrel{\text{\color{blue}$V$ bijective}}{=} \{ U\mu:  \mu= (\mu_1,\ldots, \mu_r,0,\ldots,0)^\top,~ (\mu_1,\ldots, \mu_r)^\top \in \mathbb{R}^r \}\\
%&= \text{span}(u_1,\ldots,u_r).
%\end{align*}
%Since $u_1, \ldots, u_r$ orthonormal (thus independent) we find $\dim(\text{Im}(A)) = r$.~\\~\\
%%

% we can show $iii) \Rightarrow i)$. For this purpose, let $A$ have exactly $r$ nonzero singular values. Now assume that $A$ has more than $r$ independent columns, say $k > r$. Then, since i) implies ii) we have that $\text{dim}\text{Im}(A) = k$ and since ii) implies iii) we have that $A$ has exactly $k$ nonzero singular values which is a contradiction!

}
