% !TeX spellcheck = en_US
\textbf{Gram-Schmidt algorithm ($QR$ factorization)}

{\color{navy}
The Gram-Schmidt algorithm is an algorithm that can be used to compute a reduced (sometimes also called ``thin'' or ``economic'') QR-decomposition of a matrix $A \in \mathbb{R}^{m\times n}$ with $m\geq n$ and $\text{rank}(A) = n$, i.e., of a matrix whose columns are linearly independent.\\
The basic idea is to successively 
built up an orthonormal system from a given set of linearly independent vectors; in our case the columns of 
$A = [a_1, \dots, a_n] \in \mathbb{R}^{m\times n}$.
We choose the first column as starting point for the algorithm and set $\widetilde{q_1} := a_1$. 
Of course, in order to generate an orthogonal matrix $Q$ we have to rescale the vector and set
$q_1 := \frac{\widetilde{q_1}}{\| \widetilde{q_1} \|}$.
The successive vectors $\widetilde{q}_k$ are generated by
subtracting all the ``shares'' $a_k^\top q_\ell\cdot q_\ell$ (=$\text{proj}_{q_\ell}(a_k)$) of the previous vectors $q_\ell$ from the column $a_k$, i.e.,
$$
\widetilde{q}_k := a_k - \sum_{\ell = 1}^{k-1} a_k^\top q_\ell \,\, q_\ell.
$$


The following algorithm computes a \textit{reduced} QR-decomposition of some matrix $A \in \mathbb{R}^{m \times n}$.\\
~\\
$r_{11} \gets \| a_1 \|$\\
$q_1 \gets \frac{a_1}{r_{11}}$\\
~\\
\textbf{for} $k = 2, \dots, n$  \\
{\color{white}ind}\textbf{for} $\ell = 1,\dots, k-1$ \\
{\color{white}ind}{\color{white}ind}$r_{\ell k} \gets a_k^\top q_\ell$	\\
~\\
{\color{white}ind}$\widetilde{q}_k \gets a_k - \sum _{\ell=1}^{k-1} r_{\ell k} \, q_\ell$\\
{\color{white}ind}$r_{kk} \gets \| \widetilde{q}_k \|$\\
{\color{white}ind}$q_k \gets \frac{\widetilde{q}_k}{r_{kk}}$\\
}
~\\
\textbf{Task:} 
\begin{enumerate}
	\item Implement the Gram-Schmidt algorithm as a function \verb|qr_factor(A)|, which takes a matrix $A$ as input and returns the matrices $\widehat{Q}$ and $\widehat{R}$.
	\item Run your algorithm on an example matrix (e.g., \texttt{numpy.random.rand(m,n)}) and test your result by computing $\widehat{Q}^\top \widehat{Q}$ and $\widehat{Q}\widehat{R} - A$, where the first should yield the identity and the latter a zero-matrix.
	\item Find a SciPy routine to compute the $QR$ decomposition (for the reduced $QR$ you may need to set the parameters accordingly).
\end{enumerate}

\textit{Hint: } You can use \texttt{numpy.allclose()} to check whether two \texttt{numpy.ndarray}'s are equal up to a certain tolerance.
