{
    "filename": "Questions_1.tex",
    "title": "",
    "subtitle": "",
    "coding": "",
    "mathFields": "",
    "tags": "",
    "relatedExercises": "",
    "solutionLength": "",
    "task": "Answer the following questions.\n\\begin{enumerate}\n\t\\item How is \\textit{injectivity} of a function $f\\colon X \\to Y$ defined?\n\t%\n\t\\item How is a \\textit{scalar product} $P\\colon \\mathbb{R}^n \\times \\mathbb{R}^n \\mapsto \\mathbb{R}$ defined?\n\t%\n\t\\item Assume you are given the singular value decomposition (SVD)\n\t$U \\Sigma V^\\top = A$ of some matrix $A \\in \\mathbb{R}^{m \\times n}$. Determine the pseudoinverse $A^+$ of $A$ with the help of the SVD. Proof that $A^+ = A^{-1}$, if $A$ is invertible (\\textit{hint:} note that $m=n$ in this case).\n\t\n\t\\item Let $A \\in \\mathbb{R}^{n \\times n}$ be a matrix. Are the notions of\n\tinjectivity and surjectivity of $A$ equivalent? Give a short justification.\n\t\n\t\\item What is the normal equation? Where is it applied?\n\t\n\t\\item Give an example of a vector space other than $\\mathbb{R}^n$? \n\t\n\t\\item Let $V$ be a vector space over the field $\\mathbb{F}$. Give the definition of a basis.\n\n\\end{enumerate}",
    "solution": "{\\color{solution}\n\\begin{enumerate}\n\t\\item $~~\\textcolor{exampoints}{(1P)}~~f:X\\rightarrow Y~\\text{injective}~~:\\Leftrightarrow~~f(x)=f(y)~~\\Rightarrow~~x=y~~\\forall x,y\\in X$\n\t\n\t\\item $P:\\mathbb{R}^n\\times\\mathbb{R}^n\\rightarrow \\mathbb{R}$ scalar product, if\n\t\\begin{align*}\n\t&\\textcolor{exampoints}{(1P)}~~\\text{i)}~~\\forall x,y\\in\\mathbb{R}^n:~P(x,y)=P(y,x)\\\\\n\t&\\textcolor{exampoints}{(1P)}~~\\text{ii)}~~\\forall x\\in\\mathbb{R}^n\\setminus\\{0\\}:~P(x,x)>0\\\\\n\t&\\textcolor{exampoints}{(1P)}~~\\text{iii)}~~\\forall x,y,z\\in\\mathbb{R}^n:~P(x,y+z)=P(x,y)+P(x,z)\\\\\n\t&\\textcolor{exampoints}{(1P)}~~\\text{iv)}~~\\forall x,y\\in\\mathbb{R}^n,\\lambda\\in\\mathbb{R}:~P(x,\\lambda y)=\\lambda P(x,y)\n\t\\end{align*}\n\t\n\t\\item \n\t\\begin{itemize}\n\t\t\\item \n\t\t$\\textcolor{exampoints}{(1P)}$ pseudoinverse: $A^+=V\\Sigma^+U^T$, where $\\Sigma^+=\\text{diag}(\\frac{1}{\\sigma_i}:~\\sigma_i\\neq 0)$\n\t\t\\item \n\t\tLet $A\\in GL_n(\\mathbb{R})$, then $\\textcolor{exampoints}{(1P)}~\\sigma_{ii}\\neq 0~\\forall i$ and $A^{-1}=(U\\Sigma V^T)^{-1}=V\\Sigma^{-1}U^T~\\textcolor{exampoints}{(1P)}~\\\\\n\t\t(V,U~\\text{orthogonal})$. Since $\\Sigma^{-1}=~\\text{diag}(\\frac{1}{\\sigma_i})=\\Sigma^+$ we find $A^{-1}=A^+~~\\textcolor{exampoints}{(1P)}$\n\t\\end{itemize}\n\t\n\t\\item \n\t\n\t\\item \n\t\n\t\\item $~~\\textcolor{exampoints}{(1P)}~~\\mathbb{R}^{m\\times n},~~P_n(\\mathbb{R}):=\\{x\\mapsto\\sum_{i=0}^{n}\\alpha_ix^i:~(\\alpha_0,\\dots,\\alpha_n)\\in\\mathbb{R}^{n+1}\\}$\n\t\n\t\\item \n\t$\\{v_1,\\dots,v_n\\}\\subset V$ basis :$\\Leftrightarrow$\n\t\\begin{align*}\n\t&\\textcolor{exampoints}{(1P)}~~\\text{i)}~~\\{v_1,\\dots,v_n\\}~\\text{linearly independent}~~(\\Leftrightarrow~\\sum \\lambda_jv_j=0~\\Rightarrow~\\lambda_j=0~\\forall~j\\\\\n\t&\\textcolor{exampoints}{(1P)}~~\\text{ii)}~~\\text{span}(v_1,\\dots,v_n)=V~~\\textcolor{blue}{(\\Leftrightarrow~\\{\\sum \\lambda_jv_j:~\\lambda_j\\in\\mathbb{R}\\}=V)}\n\t\\end{align*}\n\\end{enumerate}\n}"
}