{
    "filename": "EigenvaluesAndPositivity.tex",
    "title": "",
    "subtitle": "",
    "coding": "",
    "mathFields": "",
    "tags": "",
    "relatedExercises": "",
    "solutionLength": "",
    "task": "% !TeX spellcheck = en_US\n\\textbf{Eigenvalues and Positivity of a Matrix}\n\n{\\color{navy}\n\t\\textbf{Definition.} A matrix $A\\in \\mathbb{R}^{n\\times n}$ is called positive definite (semi-definite) it $x^TAx > 0 ~~(\\geq 0)$ for all $x \\in \\mathbb{R}^n\\setminus\\{0\\}$.\\\\[10pt]}\nLet $A\\in \\mathbb{R}^{n\\times n}$ be any matrix. Please show:\n\\begin{enumerate}\n\t\\item If $A$ is positive definite (semi-definite), then $\\lambda > 0$ ($\\geq 0$) for all eigenvalues $\\lambda \\in \\sigma(A)$.~\\\\ (\\textit{Hint:} Rayleigh quotient.)\n\t\\item The reverse is not true: Find an example of a matrix, which has positive eigenvalues, but is \\textit{not} positive definite.\\\\\n\t(\\textit{Hint:} Consider, e.g., a triangular $2 \\times 2$ matrix.)\n\t\\item The reverse is true for symmetric matrices: Let $A$ be \\textit{symmetric} and $\\lambda > 0$ ($\\geq 0$) for all eigenvalues $\\lambda \\in \\sigma(A)$, then $A$ is positive definite (semi-definite).\\\\\n\t(\\textit{Hint:} Eigendecompostion.)\n\t\\item Let $A$ be \\textit{symmetric}, then $A$ is invertible if and only if $\\lambda \\neq 0$ for all eigenvalues $\\lambda \\in \\sigma(A)$.~\\\\ (\\textit{Hint:} Eigendecompostion.)\n\\end{enumerate}\n",
    "solution": "% !TeX spellcheck = en_US\n{\n\\color{solution}\n\\begin{enumerate}\n\t\\item % {\\color{red}Note: This only works with the correct complex norm and inner product! If symmetry is assumed then everything is fine! }\\\\\n\tLet $A$ be positive definite (semi--definite) and let $(\\lambda, v)$ be an eigenpair of $A$. Then by using the Rayleigh quotient we find\n\t$$\\lambda = \\frac{v^\\top A v}{v^\\top v} = \\frac{v^\\top A v}{\\|v\\|_2^2}~~{\\color{cyan}\\tfrac{> 0~~ (\\geq 0)}{> 0 ~ \\text{since}~v\\neq 0  }} ~~> 0~~ (\\geq 0). $$\n%\t\n%\tProof by contradiction:\\\\\n%\tLet $A$ be $\\underbrace{\\text{positive definite}}_{\\textcolor{blue}{:\\Leftrightarrow x^TAx>0~\\forall x\\neq 0}}$ and assume $\\lambda\\leq0$ for some $\\underbrace{\\lambda\\in\\sigma(A)}_{\\textcolor{blue}{:\\Leftrightarrow \\exists v\\neq 0: Av=\\lambda v}}$ with eigenvector $v\\neq 0$.\\\\\n%\tThen we find\n%\t$$\n%\tv^T\\underbrace{Av}_{\\textcolor{blue}{=\\lambda v}} \n%\t= \\lambda v^Tv\n%\t= \\underbrace{\\lambda}_{\\textcolor{blue}{\\leq0}}\\underbrace{\\|{v}\\|_2^2}_{\\textcolor{blue}{>0}} ~\\leq 0~ ~~~\\textcolor{red}{\\text{[contradiction to the positivity of A]}}.$$\\\\\n%\t(Analogous proof for $A$ positive semi-definite.)\n\t\\item Take for example \n\t$$A=\\begin{pmatrix}\n\t1&-4\\\\\n\t0&2\n\t\\end{pmatrix} $$\n\twhich has positive eigenvalues $\\sigma(A)=\\{1,2\\}$, but for $x=(1,1)^\\top$ we have\n\t\t$$x^\\top A x = -3+2 = -1 < 0. $$\n\t\\item \tFor symmetric $A\\in\\mathbb{R}^{n\\times n}$ we find an orthogonal matrix $Q\\in\\mathbb{R}^{n\\times n}$ and diagonal matrix $\\Lambda = \\text{diag}(\\lambda_1,\\ldots,\\lambda_n)$ with $\\lambda_i\\in\\sigma(A)$, so that   $$A=Q\\Lambda Q^T ~~~~\\text{(eigendecomposition)}.$$\n\tSince $Q$ is orthogonal, any vector $x \\in \\R^n$ can be written as $x = Ix=QQ^\\top x=Q\\mu$, with coordinates $\\mu := Q^\\top x$ where $\\mu \\neq 0$ for $x\\neq 0$. Therefore \n\t\\begin{equation*}\n\t\\begin{aligned}\n\tx^\\top A x = \\mu^\\top Q^\\top Q\\Lambda Q^\\top Q \\mu = \\mu^\\top \\Lambda \\mu = \\sum_{i=1}^n \\mu_i^2 \\lambda_i \\geq 0.\n\t\\end{aligned}\n\t\\end{equation*}\n\tWe have ``$>$'' if $x \\neq 0$.\n\t\\item \n\tFor symmetric $A\\in\\mathbb{R}^{n\\times n}$ we find an orthogonal matrix $Q\\in\\mathbb{R}^{n\\times n}$ and diagonal matrix $\\Lambda = \\text{diag}(\\lambda_1,\\ldots,\\lambda_n)$ with $\\lambda_i\\in\\sigma(A)$, so that   $$A=Q\\Lambda Q^T ~~~~\\text{(eigendecomposition)}.$$\n\tTherefore:\n\t\\begin{center}\n\t\t$A$ invertible \n\t\t~~$\\stackrel{(*)}{\\Leftrightarrow}\\ \\ \\Lambda$ invertible \n\t\t~~$\\stackrel{(**)}{\\Leftrightarrow}\\ \\ \\lambda\\neq 0\\ \\ \\forall\\lambda\\in\\sigma(A)$.\n\t\\end{center}\n\t\\begin{itemize}\n\t\t\\item[$(*)$]  product of matrices is invertible if all factors are invertible and orthogonal matrices are invertible with inverse $Q^T=Q^{-1}$\n\t\t\\item[$(**)$] diagonal matrices are invertible, if and only if diagonal elements are nonzero\n\t\\end{itemize}\nExample: $A$ symmetric and positive definite (spd) $\\Rightarrow$ $A$ invertible.\n\\end{enumerate}\n}",
    "id": ""
}