{\color{solution}
\begin{enumerate}
	\item Let $k < j$. Since $q_k^\top q_j = \frac{1}{ \|\widehat{q}_j\|_2} q_k^\top \widehat{q}_j$ it suffices to show that $q_k^\top \widehat{q}_j=0$. Now let $v:=Aq_{j-1}$, then
	\begin{align*}
q_k^\top 	\widehat{q}_j  = q_k^\top \left(v - \sum_{\ell = 1}^{j-1} q_\ell^\top v  \cdot q_\ell\right)  
	= q_k^\top v - \sum_{\ell = 1}^{j-1} q_\ell^\top v   \cdot \underbrace{q_k^\top q_\ell}_{= \delta_{k\ell}} 
	=q_k^\top v -  q_k^\top v\cdot 1
	=0.  
	\end{align*}
	\item By definition of the matrix product we obtain, for $1\leq \ell,j \leq r$,
	\begin{align*}
	  H_r^{\ell j} = (Q_r^\top AQ_r)_{\ell j} = q_\ell ^\top Aq_j  .
	\end{align*}
	These are precisely the projection lengths that are computed during the Arnoldi iteration. Since by definition $Aq_j$ can be uniquely generated by $q_1,\ldots, q_{j+1}$ (i.e., $Aq_j=\sum_{\nu = 1}^{j+1}\lambda_\nu q_\nu$ for some coordinates $\lambda_\nu$), we have, for all $\ell> j+1$,
	
	$$H_r^{\ell j} = q_\ell ^\top Aq_j = q_\ell^\top \left(\sum_{\nu = 1}^{j+1}\lambda_\nu q_\nu\right) =\sum_{\nu = 1}^{j+1}\lambda_\nu q_\ell^\top q_\nu = 0 .$$ 
	In particular, $H_r$ is an upper \textit{Hessenberg} matrix (having precisely one subdiagonal).
	\item If $A$ is symmetric, then $H_r = Q_r^\top A Q_r$ is symmetric, so that it simplifies to a tridiagonal matrix, i.e., $$H_r^{\ell j} =q_\ell ^\top Aq_j = 0$$ for all $\ell,j$ with $|\ell-j|> 2$. Then Arnoldi becomes Lanczos by accounting for the simplification
	\begin{align*}
	 \widehat{q}_j 
	 &= Aq_{j-1} - \sum_{\ell = 1}^{j-1} q_\ell^\top(Aq_{j-1})  \cdot q_\ell\\
	 &= Aq_{j-1} - \sum_{\ell = j-2}^{j-1} q_\ell^\top(Aq_{j-1})  \cdot q_\ell\\
	 &= Aq_{j-1} - q_{j-2}^\top(Aq_{j-1})  \cdot q_{j-2} - q_{j-1}^\top(Aq_{j-1})\cdot q_{j-1}.
	\end{align*}
  \item Since $Q_n^TAQ_n \in \mathbb{R}^{n \times n}$ is orthogonally similar to $A$, it has the same eigenvalues as $A$. 
\end{enumerate}



}