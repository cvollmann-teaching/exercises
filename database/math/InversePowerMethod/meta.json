{
    "filename": "InversePowerMethod.tex",
    "title": "",
    "subtitle": "",
    "coding": "",
    "mathFields": "",
    "tags": "Linear Algebra, Eigenvalues",
    "relatedExercises": "",
    "solutionLength": "",
    "task": "\\textbf{Inverse Power Method}\n\n \\label{ex:inversepowertheory}\nLet $A \\in \\mathbb{R}^{n \\times n}$ be a matrix with eigenvalues $\\lambda_j$ for $j \\in  \\{1,\\dots,n\\}$ with the property\n\\begin{align*}\n|\\lambda_n| \\geq \\dots \\geq |\\lambda_{i+1}|  > |\\lambda_i| > |\\lambda_{i-1}| \\geq \\dots \\geq |\\lambda_1|. \n\\end{align*}\nLet $\\hat{\\lambda} \\approx \\lambda_i$ be a \\textit{good guess} for the eigenvalue $\\lambda_i$, which means\n\\begin{align}\n0 < |\\lambda_i - \\hat{\\lambda} | < |\\lambda_j -  \\hat{\\lambda} | ~~\\forall~ i \\neq j.\n\\end{align}\nOr in other words, $\\hat{\\lambda}$ is closer to $\\lambda_i$ (in absolute terms) than any other eigenvalue.\\\\\nLet us define $$B := (A - \\hat{\\lambda} I). $$\n\n\\begin{enumerate}\n\t\\item Show that $(\\lambda_i - \\hat{\\lambda})^{-1}$  is (in magnitude) the largest eigenvalue of the matrix $B^{-1}$.\n\t\n%\t\\textit{Hint: } Use results from Sheet 5, Exercise 31.\n\t\\item Let $x^0 \\in \\mathbb{R}^n$. With respect to $A$, the iteration\n\t\\begin{align}\n\tx^{k+1} := \\frac{B^{-1} x^k}{\\|B^{-1} x^k\\|} \\label{inv_powerit}\n\t\\end{align}\n\tfor $k \\geq 0$ is called \\textit{inverse power iteration}. Under which condition on $x^0$ does this iteration converge and what is the limit?\n\t\n\t\\textit{Hint:} Apply the theorem about the power method from the lecture.\n%\t\\item Why is the \\textit{inverse power iteration} computationally more expensive than the \\textit{power iteration}? What could help \n%\tto drastically reduce the required computational effort?\n%\t\n%\t\\textit{Hint: } Sheet 3, Exercise 21 (iii) deals with a similar problem.\n\\end{enumerate}",
    "solution": "{\\color{solution}\n$\\textcolor{blue}{\\text{\\underline{The message here is:}}}$~\nUnder the assumption of having a ``good'' guess for $\\lambda_i$, we find the ``exact'' eigenvector (and -value) with the help of the \\textit{inverse power iteration}. However note that it is computationally more expensive, because you have to solve a linear system in each iteration.\\\\\n\\\\\nWe have $A\\in\\mathbb{R}^{n\\times n}$ with eigenvalues $|\\lambda_n|\\geq\\dots\\geq|\\lambda_{i+1}|>|\\lambda_i|>|\\lambda_{i-1}|\\geq\\dots\\geq|\\lambda_1|$ and corresponding eigenvectors $v_j \\neq 0$. Also we have $\\hat{\\lambda}\\approx\\lambda_i$ so that $$0<|\\lambda_i-\\hat{\\lambda}|<|\\lambda_j-\\hat{\\lambda}|~~\\forall~i\\neq j~\\textcolor{blue}{(*)}.$$\nNow define $B:=(A-\\hat{\\lambda}I)$.\n\\begin{enumerate}\n\t\\item \n\tWe show, that $(\\lambda_i -\\hat{\\lambda})^{-1}$ is the largest eigenvalue of $B^{-1}$.\n\t\\begin{itemize}\n\t\t\\item [(i)] \n\t\tFor all $j$ we have that $(\\lambda_j-\\hat{\\lambda})$ is an eigenvalue of $B$ to the same eigenvector $v_j$ (previous sheets).\n\t\t\\item [(ii)] Also $B$ is invertible, otherwise there would exist $v\\neq 0$, so that $Bv=0$, which would imply $\\hat{\\lambda}$ eigenvalue of $A$, which would contradict the assumption: $|\\lambda_j-\\hat{\\lambda}|>0~\\forall j~~\\Rightarrow~~|\\lambda_j-\\hat{\\lambda}|\\neq 0~\\forall j$. Thus $\\frac{1}{\\lambda_j-\\hat{\\lambda}}$ is an eigenvalue of $B^{-1}$ for all $j$ to the same  eigenvector $v_j$ (see previous sheets).\\\\ By $\\textcolor{blue}{(*)}$ we then find that $$\\frac{1}{|\\lambda_i-\\hat{\\lambda}|}>\\frac{1}{|\\lambda_j-\\hat{\\lambda}|}~\\forall j ~~\\textcolor{violet}{(\\sharp)}.$$\n\t\\end{itemize}\n\t\\item \n\tLet $v_1$ be an eigenvector to the eigenvalue $(\\lambda_i-\\hat{\\lambda})^{-1}$, and $x^0$ an orthogonal initial guess, i.e., $(x^0,v_1)\\neq 0$, then due to $\\textcolor{violet}{(\\sharp)}$ we find by the theorem about the power method that\n\t$$\n\t\\frac{B^{-1}x^k}{\\|B^{-1}x^k\\|}\\rightarrow v_1.\n\t$$\n\t\\underline{Note:} $v_1$ is eigenvector of\n\t\\begin{itemize}\n\t\t\\item \n\t\t...$A$ to the eigenvalue $\\lambda_i$.\n\t\t\\item \n\t\t...$B=A-\\hat{\\lambda}_iI$ to the eigenvalue $\\lambda_i-\\hat{\\lambda}$.\n\t\t\\item \n\t\t...$B^{-1}=(A-\\hat{\\lambda}_iI)^{-1}$ to the eigenvalue $(\\lambda_i-\\hat{\\lambda})^{-1}$.\n\t\\end{itemize}\n%\t\\item \n%\tIt is computationally more expensive, because you have to solve a linear system in each iteration.\n\\end{enumerate}\n}",
    "id": ""
}