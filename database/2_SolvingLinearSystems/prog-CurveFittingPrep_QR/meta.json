{
    "filename": "prog-CurveFittingPrep_QR.tex",
    "title": "",
    "subtitle": "",
    "coding": "",
    "mathFields": "",
    "tags": "",
    "relatedExercises": "",
    "solutionLength": "",
    "task": "% !TeX spellcheck = en_US\n\\textbf{Curve Fitting using reduced $QR$ Decomposition}\n\n{\n\\color{navy}\nLet $A \\in \\mathbb{R}^{m\\times n}$ be a matrix with $m\\geq n$ and linearly independent columns and let $b \\in \\mathbb{R}^m$. Solving Least Squares Problems of the form\n$$\\min_{x\\in\\mathbb{R}^n} \\|Ax-b\\|^2$$\nis equivalent to solving the so-called \\textit{normal equation} (derivation follows later in the lecture)\n$$A^\\top A x = A^\\top b. $$\nThis is a linear system and we can apply a ``factor and solve'' approach. Specifically, assume we have the reduced $\\widehat{Q}\\widehat{R}$, where $\\widehat{R}$ is invertible since $A$ has full column rank by assumption.\nNow, inserting $A=\\widehat{Q}\\widehat{R}$ into the normal equation gives\n$$A^TAx=A^Tb~\\Leftrightarrow~\\widehat{R}^T\\widehat{R}x=\\widehat{R}^T\\widehat{Q}^Tb~\\Leftrightarrow~\\widehat{R}x=\\widehat{Q}^Tb.$$\nThus, we can finally compute a least squares solution by solving a triangular system\n$$\\widehat{R}x = \\widehat{Q}^Tb.$$\n\\textit{Interesting Observation:} Applying a ``factor and solve'' approach to $Ax=b$ results in the same the systems!\n}\n~\\\\~\\\\\n\\textbf{Task}\\\\\nAssume you were given some \\verb|numpy.ndarray| called ``\\verb|data|'' containing measurements $(z_1,y_1),\\ldots, (z_m,y_m) \\in \\mathbb{R}\\times\\mathbb{R}$. Further assume that this data has shape \\verb|(2,m)| so that the first row \\verb|data[0,:]| contains the $z_i$ values and the second row \\verb|data[1,:]| contains the $y_i$ values.\n\\begin{enumerate}\n\t\\item Implement a function \\verb|poly_curve_fit(data, p)| which computes a polynomial fit to the data.\\\\ ~\\\\\n\tThe \\textbf{input} \\verb|data| shall have the form as described above and \\verb|p| shall determine the polynomial used to fit the data. More precisely, \\verb|p| shall be a list \\verb|[p1,..., pn]| containing $n \\leq m$ \\textit{distinct} natural numbers between $0$ and $m-1$ which determine the polynomial model $f$ by\n\t\\begin{align*}\n\t  f(z) = c_1 z^{p_1} + c_2 z^{p_2} + \\ldots +  c_k z^{p_n} = \\sum_{j=1}^n c_j f_j(z) ~~~\\text{with}~~~f_j(z) := z^{p_j}.\n\t\\end{align*}\n\tWith other words, the input \\verb|p| determines which \\textit{monomials} $z^{p}$ we want to use for our model. For example, \\verb|p = [0,1]| amounts for a linear model\n\t\\begin{align*}\n\t\tf(z) = c_1 z^{p_1} + c_2 z^{p_2}  = c_1 z^0 + c_2 z^1 = c_1 + c_2 z^1.\n\t\\end{align*}\n\tThen the \\textbf{function} \\verb|poly_curve_fit(data, p)| shall determine appropriate coefficients $c_1,\\ldots,c_n$ by following this recipe:\n\t\\begin{enumerate}\n\t\t\\item Assemble the vector $b = (y_1,\\ldots,y_m)\\in \\mathbb{R}^m$.\n\t\t\\item Assemble the matrix $A = (a_{ij})_{ij} \\in \\mathbb{R}^{m \\times n}$, where $a_{ij} := f_j(z_i)$.\n\t\t\\item Solve the least squares problem $\\min_x \\|Ax-b\\|^2$ via the normal equation above by using the functions \\texttt{qr\\_factor(A)} and \\texttt{solve\\_tri((Q,R),b)} from previous exercises (or appropriate SciPy routines).\\\\ \n\t\t{\\small \\textit{Remark:} One can show that the columns of $A$ are independent if the $z_i$ are \\textit{distinct} (also see \\textit{Vandermonde matrix})!}\n\t\t\\item Plot the measurements and the fitting polynomial into one figure.\n\t\\end{enumerate}\n\tThe function shall \\textbf{output} the solution parameters $x = (c_1,\\ldots, c_n)$.\n\t\\item Test your routine by fitting the data \n\t\\begin{center}\n\t\t\\begin{tabular}{l|c c c c c}\n\t\t\tz&-2&-1&0&1&2\\\\\n\t\t\t\\hline\n\t\t\ty&-2&1&-1&2&6\n\t\t\\end{tabular}\n\t\\end{center}\nwith different polynomials of your choice.\n\t\\item Find a Scipy routine to solve the least squares problem $\\min_x \\|Ax-b\\|^2$. If you want, you can extend the parameter interface \\verb|poly_curve_fit(data, p, own=True)| by an optional parameter, for example \\texttt{own=True}, which you can use to switch between either our approach with a (reduced) $QR$-decomposition \n\tor a SciPy routine to solve the least squares problem.\n\\end{enumerate}\n",
    "solution": "\\lstinputlisting[numbers=none]{prog-CurveFittingPrep_QR_solution.py}\n",
    "id": ""
}